{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=center><font size = 5>Introduction to Deep Learning Peer Graded Assignment: Build a Regression Model in Keras</font></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project is the final assignement of the Introduction to Deep Learning Course which itself the 3rd course of the IBM AI Engineering professional track containing 6 courses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installing Libraries (uncomment if necessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install keras\n",
    "#pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
       "0   540.0                 0.0      0.0  162.0               2.5   \n",
       "1   540.0                 0.0      0.0  162.0               2.5   \n",
       "2   332.5               142.5      0.0  228.0               0.0   \n",
       "3   332.5               142.5      0.0  228.0               0.0   \n",
       "4   198.6               132.4      0.0  192.0               0.0   \n",
       "\n",
       "   Coarse Aggregate  Fine Aggregate  Age  Strength  \n",
       "0            1040.0           676.0   28     79.99  \n",
       "1            1055.0           676.0   28     61.89  \n",
       "2             932.0           594.0  270     40.27  \n",
       "3             932.0           594.0  365     41.05  \n",
       "4             978.4           825.5  360     44.30  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_data = pd.read_csv('concrete_data.csv')\n",
    "concrete_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick quality checks on data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>281.167864</td>\n",
       "      <td>73.895825</td>\n",
       "      <td>54.188350</td>\n",
       "      <td>181.567282</td>\n",
       "      <td>6.204660</td>\n",
       "      <td>972.918932</td>\n",
       "      <td>773.580485</td>\n",
       "      <td>45.662136</td>\n",
       "      <td>35.817961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>104.506364</td>\n",
       "      <td>86.279342</td>\n",
       "      <td>63.997004</td>\n",
       "      <td>21.354219</td>\n",
       "      <td>5.973841</td>\n",
       "      <td>77.753954</td>\n",
       "      <td>80.175980</td>\n",
       "      <td>63.169912</td>\n",
       "      <td>16.705742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>102.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>121.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>801.000000</td>\n",
       "      <td>594.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>192.375000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>164.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>932.000000</td>\n",
       "      <td>730.950000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>23.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>272.900000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>968.000000</td>\n",
       "      <td>779.500000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>34.445000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>350.000000</td>\n",
       "      <td>142.950000</td>\n",
       "      <td>118.300000</td>\n",
       "      <td>192.000000</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>1029.400000</td>\n",
       "      <td>824.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>46.135000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>540.000000</td>\n",
       "      <td>359.400000</td>\n",
       "      <td>200.100000</td>\n",
       "      <td>247.000000</td>\n",
       "      <td>32.200000</td>\n",
       "      <td>1145.000000</td>\n",
       "      <td>992.600000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>82.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Cement  Blast Furnace Slag      Fly Ash        Water  \\\n",
       "count  1030.000000         1030.000000  1030.000000  1030.000000   \n",
       "mean    281.167864           73.895825    54.188350   181.567282   \n",
       "std     104.506364           86.279342    63.997004    21.354219   \n",
       "min     102.000000            0.000000     0.000000   121.800000   \n",
       "25%     192.375000            0.000000     0.000000   164.900000   \n",
       "50%     272.900000           22.000000     0.000000   185.000000   \n",
       "75%     350.000000          142.950000   118.300000   192.000000   \n",
       "max     540.000000          359.400000   200.100000   247.000000   \n",
       "\n",
       "       Superplasticizer  Coarse Aggregate  Fine Aggregate          Age  \\\n",
       "count       1030.000000       1030.000000     1030.000000  1030.000000   \n",
       "mean           6.204660        972.918932      773.580485    45.662136   \n",
       "std            5.973841         77.753954       80.175980    63.169912   \n",
       "min            0.000000        801.000000      594.000000     1.000000   \n",
       "25%            0.000000        932.000000      730.950000     7.000000   \n",
       "50%            6.400000        968.000000      779.500000    28.000000   \n",
       "75%           10.200000       1029.400000      824.000000    56.000000   \n",
       "max           32.200000       1145.000000      992.600000   365.000000   \n",
       "\n",
       "          Strength  \n",
       "count  1030.000000  \n",
       "mean     35.817961  \n",
       "std      16.705742  \n",
       "min       2.330000  \n",
       "25%      23.710000  \n",
       "50%      34.445000  \n",
       "75%      46.135000  \n",
       "max      82.600000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cement                0\n",
       "Blast Furnace Slag    0\n",
       "Fly Ash               0\n",
       "Water                 0\n",
       "Superplasticizer      0\n",
       "Coarse Aggregate      0\n",
       "Fine Aggregate        0\n",
       "Age                   0\n",
       "Strength              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concrete_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part A - Build a Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reusing code from one of the lab\n",
    "def regression_model_custom(n_pred,hidden_layers=1, nodes=10):\n",
    "### Customised the function so that I can build a model with more or less hidden layers and with more or less nodes.\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(nodes, activation='relu', input_shape=(n_pred,))) #Fist Hidden Layer\n",
    "    for i in range(2,hidden_layers+1):\n",
    "        model.add(Dense(nodes, activation='relu')) #Other hidden layers if any\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    # compile model\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_model=regression_model_custom(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Split the data into training and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function train_test_split in module sklearn.model_selection._split:\n",
      "\n",
      "train_test_split(*arrays, **options)\n",
      "    Split arrays or matrices into random train and test subsets\n",
      "    \n",
      "    Quick utility that wraps input validation and\n",
      "    ``next(ShuffleSplit().split(X, y))`` and application to input data\n",
      "    into a single call for splitting (and optionally subsampling) data in a\n",
      "    oneliner.\n",
      "    \n",
      "    Read more in the :ref:`User Guide <cross_validation>`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    *arrays : sequence of indexables with same length / shape[0]\n",
      "        Allowed inputs are lists, numpy arrays, scipy-sparse\n",
      "        matrices or pandas dataframes.\n",
      "    \n",
      "    test_size : float, int or None, optional (default=None)\n",
      "        If float, should be between 0.0 and 1.0 and represent the proportion\n",
      "        of the dataset to include in the test split. If int, represents the\n",
      "        absolute number of test samples. If None, the value is set to the\n",
      "        complement of the train size. If ``train_size`` is also None, it will\n",
      "        be set to 0.25.\n",
      "    \n",
      "    train_size : float, int, or None, (default=None)\n",
      "        If float, should be between 0.0 and 1.0 and represent the\n",
      "        proportion of the dataset to include in the train split. If\n",
      "        int, represents the absolute number of train samples. If None,\n",
      "        the value is automatically set to the complement of the test size.\n",
      "    \n",
      "    random_state : int, RandomState instance or None, optional (default=None)\n",
      "        If int, random_state is the seed used by the random number generator;\n",
      "        If RandomState instance, random_state is the random number generator;\n",
      "        If None, the random number generator is the RandomState instance used\n",
      "        by `np.random`.\n",
      "    \n",
      "    shuffle : boolean, optional (default=True)\n",
      "        Whether or not to shuffle the data before splitting. If shuffle=False\n",
      "        then stratify must be None.\n",
      "    \n",
      "    stratify : array-like or None (default=None)\n",
      "        If not None, data is split in a stratified fashion, using this as\n",
      "        the class labels.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    splitting : list, length=2 * len(arrays)\n",
      "        List containing train-test split of inputs.\n",
      "    \n",
      "        .. versionadded:: 0.16\n",
      "            If the input is sparse, the output will be a\n",
      "            ``scipy.sparse.csr_matrix``. Else, output type is the same as the\n",
      "            input type.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> import numpy as np\n",
      "    >>> from sklearn.model_selection import train_test_split\n",
      "    >>> X, y = np.arange(10).reshape((5, 2)), range(5)\n",
      "    >>> X\n",
      "    array([[0, 1],\n",
      "           [2, 3],\n",
      "           [4, 5],\n",
      "           [6, 7],\n",
      "           [8, 9]])\n",
      "    >>> list(y)\n",
      "    [0, 1, 2, 3, 4]\n",
      "    \n",
      "    >>> X_train, X_test, y_train, y_test = train_test_split(\n",
      "    ...     X, y, test_size=0.33, random_state=42)\n",
      "    ...\n",
      "    >>> X_train\n",
      "    array([[4, 5],\n",
      "           [0, 1],\n",
      "           [6, 7]])\n",
      "    >>> y_train\n",
      "    [2, 0, 3]\n",
      "    >>> X_test\n",
      "    array([[2, 3],\n",
      "           [8, 9]])\n",
      "    >>> y_test\n",
      "    [1, 4]\n",
      "    \n",
      "    >>> train_test_split(y, shuffle=False)\n",
      "    [[0, 1, 2], [3, 4]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(train_test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=concrete_data['Strength']\n",
    "X=concrete_data.drop(['Strength','Age'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Randomly split the data into a training and test sets by holding 30% of the data for testing.\n",
    "X_train_A, X_test_A, y_train_A, y_test_A=train_test_split(X,y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>213.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>174.7</td>\n",
       "      <td>154.8</td>\n",
       "      <td>10.2</td>\n",
       "      <td>1053.5</td>\n",
       "      <td>776.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>381.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>185.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1104.6</td>\n",
       "      <td>784.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>284.0</td>\n",
       "      <td>119.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>168.3</td>\n",
       "      <td>7.2</td>\n",
       "      <td>970.4</td>\n",
       "      <td>794.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>157.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>819.0</td>\n",
       "      <td>704.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>275.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>121.4</td>\n",
       "      <td>159.5</td>\n",
       "      <td>9.9</td>\n",
       "      <td>1053.6</td>\n",
       "      <td>777.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
       "345   213.7                 0.0    174.7  154.8              10.2   \n",
       "569   381.4                 0.0      0.0  185.7               0.0   \n",
       "960   284.0               119.7      0.0  168.3               7.2   \n",
       "927   157.0               214.0    152.0  200.0               9.0   \n",
       "334   275.1                 0.0    121.4  159.5               9.9   \n",
       "\n",
       "     Coarse Aggregate  Fine Aggregate  \n",
       "345            1053.5           776.4  \n",
       "569            1104.6           784.3  \n",
       "960             970.4           794.2  \n",
       "927             819.0           704.0  \n",
       "334            1053.6           777.5  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_A.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function fit in module keras.engine.training:\n",
      "\n",
      "fit(self, x=None, y=None, batch_size=None, epochs=1, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None, validation_freq=1, max_queue_size=10, workers=1, use_multiprocessing=False, **kwargs)\n",
      "    Trains the model for a fixed number of epochs (iterations on a dataset).\n",
      "    \n",
      "    # Arguments\n",
      "        x: Input data. It could be:\n",
      "            - A Numpy array (or array-like), or a list of arrays\n",
      "              (in case the model has multiple inputs).\n",
      "            - A dict mapping input names to the corresponding\n",
      "              array/tensors, if the model has named inputs.\n",
      "            - A generator or `keras.utils.Sequence` returning\n",
      "              `(inputs, targets)` or `(inputs, targets, sample weights)`.\n",
      "            - None (default) if feeding from framework-native\n",
      "              tensors (e.g. TensorFlow data tensors).\n",
      "        y: Target data. Like the input data `x`,\n",
      "            it could be either Numpy array(s), framework-native tensor(s),\n",
      "            list of Numpy arrays (if the model has multiple outputs) or\n",
      "            None (default) if feeding from framework-native tensors\n",
      "            (e.g. TensorFlow data tensors).\n",
      "            If output layers in the model are named, you can also pass a\n",
      "            dictionary mapping output names to Numpy arrays.\n",
      "            If `x` is a generator, or `keras.utils.Sequence` instance,\n",
      "            `y` should not be specified (since targets will be obtained\n",
      "            from `x`).\n",
      "        batch_size: Integer or `None`.\n",
      "            Number of samples per gradient update.\n",
      "            If unspecified, `batch_size` will default to 32.\n",
      "            Do not specify the `batch_size` if your data is in the\n",
      "            form of symbolic tensors, generators, or `Sequence` instances\n",
      "            (since they generate batches).\n",
      "        epochs: Integer. Number of epochs to train the model.\n",
      "            An epoch is an iteration over the entire `x` and `y`\n",
      "            data provided.\n",
      "            Note that in conjunction with `initial_epoch`,\n",
      "            `epochs` is to be understood as \"final epoch\".\n",
      "            The model is not trained for a number of iterations\n",
      "            given by `epochs`, but merely until the epoch\n",
      "            of index `epochs` is reached.\n",
      "        verbose: Integer. 0, 1, or 2. Verbosity mode.\n",
      "            0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
      "        callbacks: List of `keras.callbacks.Callback` instances.\n",
      "            List of callbacks to apply during training and validation\n",
      "            (if ).\n",
      "            See [callbacks](/callbacks).\n",
      "        validation_split: Float between 0 and 1.\n",
      "            Fraction of the training data to be used as validation data.\n",
      "            The model will set apart this fraction of the training data,\n",
      "            will not train on it, and will evaluate\n",
      "            the loss and any model metrics\n",
      "            on this data at the end of each epoch.\n",
      "            The validation data is selected from the last samples\n",
      "            in the `x` and `y` data provided, before shuffling.\n",
      "            This argument is not supported when `x` is a generator or\n",
      "            `Sequence` instance.\n",
      "        validation_data: Data on which to evaluate\n",
      "            the loss and any model metrics at the end of each epoch.\n",
      "            The model will not be trained on this data.\n",
      "            `validation_data` will override `validation_split`.\n",
      "            `validation_data` could be:\n",
      "                - tuple `(x_val, y_val)` of Numpy arrays or tensors\n",
      "                - tuple `(x_val, y_val, val_sample_weights)` of Numpy arrays\n",
      "                - dataset or a dataset iterator\n",
      "            For the first two cases, `batch_size` must be provided.\n",
      "            For the last case, `validation_steps` must be provided.\n",
      "        shuffle: Boolean (whether to shuffle the training data\n",
      "            before each epoch) or str (for 'batch').\n",
      "            'batch' is a special option for dealing with the\n",
      "            limitations of HDF5 data; it shuffles in batch-sized chunks.\n",
      "            Has no effect when `steps_per_epoch` is not `None`.\n",
      "        class_weight: Optional dictionary mapping class indices (integers)\n",
      "            to a weight (float) value, used for weighting the loss function\n",
      "            (during training only).\n",
      "            This can be useful to tell the model to\n",
      "            \"pay more attention\" to samples from\n",
      "            an under-represented class.\n",
      "        sample_weight: Optional Numpy array of weights for\n",
      "            the training samples, used for weighting the loss function\n",
      "            (during training only). You can either pass a flat (1D)\n",
      "            Numpy array with the same length as the input samples\n",
      "            (1:1 mapping between weights and samples),\n",
      "            or in the case of temporal data,\n",
      "            you can pass a 2D array with shape\n",
      "            `(samples, sequence_length)`,\n",
      "            to apply a different weight to every timestep of every sample.\n",
      "            In this case you should make sure to specify\n",
      "            `sample_weight_mode=\"temporal\"` in `compile()`. This argument\n",
      "            is not supported when `x` generator, or `Sequence` instance,\n",
      "            instead provide the sample_weights as the third element of `x`.\n",
      "        initial_epoch: Integer.\n",
      "            Epoch at which to start training\n",
      "            (useful for resuming a previous training run).\n",
      "        steps_per_epoch: Integer or `None`.\n",
      "            Total number of steps (batches of samples)\n",
      "            before declaring one epoch finished and starting the\n",
      "            next epoch. When training with input tensors such as\n",
      "            TensorFlow data tensors, the default `None` is equal to\n",
      "            the number of samples in your dataset divided by\n",
      "            the batch size, or 1 if that cannot be determined.\n",
      "        validation_steps: Only relevant if `steps_per_epoch`\n",
      "            is specified. Total number of steps (batches of samples)\n",
      "            to validate before stopping.\n",
      "        validation_steps: Only relevant if `validation_data` is provided\n",
      "            and is a generator. Total number of steps (batches of samples)\n",
      "            to draw before stopping when performing validation at the end\n",
      "            of every epoch.\n",
      "        validation_freq: Only relevant if validation data is provided. Integer\n",
      "            or list/tuple/set. If an integer, specifies how many training\n",
      "            epochs to run before a new validation run is performed, e.g.\n",
      "            `validation_freq=2` runs validation every 2 epochs. If a list,\n",
      "            tuple, or set, specifies the epochs on which to run validation,\n",
      "            e.g. `validation_freq=[1, 2, 10]` runs validation at the end\n",
      "            of the 1st, 2nd, and 10th epochs.\n",
      "        max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n",
      "            input only. Maximum size for the generator queue.\n",
      "            If unspecified, `max_queue_size` will default to 10.\n",
      "        workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
      "            only. Maximum number of processes to spin up\n",
      "            when using process-based threading. If unspecified, `workers`\n",
      "            will default to 1. If 0, will execute the generator on the main\n",
      "            thread.\n",
      "        use_multiprocessing: Boolean. Used for generator or\n",
      "            `keras.utils.Sequence` input only. If `True`, use process-based\n",
      "            threading. If unspecified, `use_multiprocessing` will default to\n",
      "            `False`. Note that because this implementation relies on\n",
      "            multiprocessing, you should not pass non-picklable arguments to\n",
      "            the generator as they can't be passed easily to children processes.\n",
      "        **kwargs: Used for backwards compatibility.\n",
      "    \n",
      "    # Returns\n",
      "        A `History` object. Its `History.history` attribute is\n",
      "        a record of training loss values and metrics values\n",
      "        at successive epochs, as well as validation loss values\n",
      "        and validation metrics values (if applicable).\n",
      "    \n",
      "    # Raises\n",
      "        RuntimeError: If the model was never compiled.\n",
      "        ValueError: In case of mismatch between the provided input data\n",
      "            and what the model expects.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(keras.models.Sequential.fit) #Quick glance at Keras documentation to check how to not further split the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see in the doc that if we do not specify a validation_split, the data won't be further splitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "721/721 [==============================] - 0s 204us/step - loss: 123230.8837\n",
      "Epoch 2/50\n",
      "721/721 [==============================] - 0s 25us/step - loss: 41295.1320\n",
      "Epoch 3/50\n",
      "721/721 [==============================] - 0s 23us/step - loss: 10422.3174\n",
      "Epoch 4/50\n",
      "721/721 [==============================] - 0s 25us/step - loss: 4528.7443\n",
      "Epoch 5/50\n",
      "721/721 [==============================] - 0s 26us/step - loss: 4138.4475\n",
      "Epoch 6/50\n",
      "721/721 [==============================] - 0s 25us/step - loss: 3957.1796\n",
      "Epoch 7/50\n",
      "721/721 [==============================] - 0s 25us/step - loss: 3767.1078\n",
      "Epoch 8/50\n",
      "721/721 [==============================] - 0s 25us/step - loss: 3586.7508\n",
      "Epoch 9/50\n",
      "721/721 [==============================] - 0s 25us/step - loss: 3411.5020\n",
      "Epoch 10/50\n",
      "721/721 [==============================] - 0s 26us/step - loss: 3241.8995\n",
      "Epoch 11/50\n",
      "721/721 [==============================] - 0s 26us/step - loss: 3077.5418\n",
      "Epoch 12/50\n",
      "721/721 [==============================] - ETA: 0s - loss: 2437.52 - 0s 26us/step - loss: 2923.0285\n",
      "Epoch 13/50\n",
      "721/721 [==============================] - 0s 25us/step - loss: 2770.8801\n",
      "Epoch 14/50\n",
      "721/721 [==============================] - 0s 22us/step - loss: 2623.3383\n",
      "Epoch 15/50\n",
      "721/721 [==============================] - 0s 24us/step - loss: 2482.2173\n",
      "Epoch 16/50\n",
      "721/721 [==============================] - 0s 23us/step - loss: 2347.0243\n",
      "Epoch 17/50\n",
      "721/721 [==============================] - 0s 25us/step - loss: 2233.7582\n",
      "Epoch 18/50\n",
      "721/721 [==============================] - ETA: 0s - loss: 2722.53 - 0s 25us/step - loss: 2104.4730\n",
      "Epoch 19/50\n",
      "721/721 [==============================] - ETA: 0s - loss: 2359.13 - 0s 23us/step - loss: 1995.7325\n",
      "Epoch 20/50\n",
      "721/721 [==============================] - ETA: 0s - loss: 2658.57 - 0s 24us/step - loss: 1884.0715\n",
      "Epoch 21/50\n",
      "721/721 [==============================] - 0s 23us/step - loss: 1787.8895\n",
      "Epoch 22/50\n",
      "721/721 [==============================] - 0s 24us/step - loss: 1695.4717\n",
      "Epoch 23/50\n",
      "721/721 [==============================] - 0s 24us/step - loss: 1605.8818\n",
      "Epoch 24/50\n",
      "721/721 [==============================] - 0s 24us/step - loss: 1521.4687\n",
      "Epoch 25/50\n",
      "721/721 [==============================] - 0s 24us/step - loss: 1444.1200\n",
      "Epoch 26/50\n",
      "721/721 [==============================] - 0s 24us/step - loss: 1373.7291\n",
      "Epoch 27/50\n",
      "721/721 [==============================] - 0s 24us/step - loss: 1306.6204\n",
      "Epoch 28/50\n",
      "721/721 [==============================] - 0s 24us/step - loss: 1242.7155\n",
      "Epoch 29/50\n",
      "721/721 [==============================] - 0s 24us/step - loss: 1184.4486\n",
      "Epoch 30/50\n",
      "721/721 [==============================] - 0s 24us/step - loss: 1128.8524\n",
      "Epoch 31/50\n",
      "721/721 [==============================] - ETA: 0s - loss: 1268.16 - 0s 24us/step - loss: 1080.8264\n",
      "Epoch 32/50\n",
      "721/721 [==============================] - 0s 24us/step - loss: 1036.6264\n",
      "Epoch 33/50\n",
      "721/721 [==============================] - 0s 25us/step - loss: 994.5550\n",
      "Epoch 34/50\n",
      "721/721 [==============================] - 0s 25us/step - loss: 953.2189\n",
      "Epoch 35/50\n",
      "721/721 [==============================] - 0s 24us/step - loss: 914.6743\n",
      "Epoch 36/50\n",
      "721/721 [==============================] - 0s 25us/step - loss: 878.5029\n",
      "Epoch 37/50\n",
      "721/721 [==============================] - 0s 28us/step - loss: 846.0016\n",
      "Epoch 38/50\n",
      "721/721 [==============================] - 0s 25us/step - loss: 810.0251\n",
      "Epoch 39/50\n",
      "721/721 [==============================] - 0s 24us/step - loss: 777.2730\n",
      "Epoch 40/50\n",
      "721/721 [==============================] - 0s 24us/step - loss: 747.2450\n",
      "Epoch 41/50\n",
      "721/721 [==============================] - ETA: 0s - loss: 841.697 - 0s 25us/step - loss: 720.0958\n",
      "Epoch 42/50\n",
      "721/721 [==============================] - ETA: 0s - loss: 925.678 - 0s 26us/step - loss: 692.2782\n",
      "Epoch 43/50\n",
      "721/721 [==============================] - 0s 24us/step - loss: 664.8346\n",
      "Epoch 44/50\n",
      "721/721 [==============================] - 0s 25us/step - loss: 641.5143\n",
      "Epoch 45/50\n",
      "721/721 [==============================] - 0s 24us/step - loss: 612.4079\n",
      "Epoch 46/50\n",
      "721/721 [==============================] - 0s 24us/step - loss: 587.3622\n",
      "Epoch 47/50\n",
      "721/721 [==============================] - 0s 26us/step - loss: 563.7322\n",
      "Epoch 48/50\n",
      "721/721 [==============================] - 0s 24us/step - loss: 539.5098\n",
      "Epoch 49/50\n",
      "721/721 [==============================] - 0s 28us/step - loss: 517.1773\n",
      "Epoch 50/50\n",
      "721/721 [==============================] - 0s 26us/step - loss: 497.8761\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x19a23473b48>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the model on the training data using 50 epochs.\n",
    "r_model.fit(X_train_A, y_train_A, epochs=50, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "309/309 [==============================] - 0s 74us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "492.02376548989304"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluate the model on the test data and compute the mean squared error between the predicted concrete strength and the actual concrete strength\n",
    "r_model.evaluate(X_test_A, y_test_A, verbose=1) #mean_squared_error using keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function predict in module keras.engine.training:\n",
      "\n",
      "predict(self, x, batch_size=None, verbose=0, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
      "    Generates output predictions for the input samples.\n",
      "    \n",
      "    Computation is done in batches.\n",
      "    \n",
      "    # Arguments\n",
      "        x: Input data. It could be:\n",
      "            - A Numpy array (or array-like), or a list of arrays\n",
      "              (in case the model has multiple inputs).\n",
      "            - A dict mapping input names to the corresponding\n",
      "              array/tensors, if the model has named inputs.\n",
      "            - A generator or `keras.utils.Sequence` returning\n",
      "              `(inputs, targets)` or `(inputs, targets, sample weights)`.\n",
      "            - None (default) if feeding from framework-native\n",
      "              tensors (e.g. TensorFlow data tensors).\n",
      "        batch_size: Integer or `None`.\n",
      "            Number of samples per gradient update.\n",
      "            If unspecified, `batch_size` will default to 32.\n",
      "            Do not specify the `batch_size` if your data is in the\n",
      "            form of symbolic tensors, generators, or\n",
      "            `keras.utils.Sequence` instances (since they generate batches).\n",
      "        verbose: Verbosity mode, 0 or 1.\n",
      "        steps: Total number of steps (batches of samples)\n",
      "            before declaring the prediction round finished.\n",
      "            Ignored with the default value of `None`.\n",
      "        callbacks: List of `keras.callbacks.Callback` instances.\n",
      "            List of callbacks to apply during prediction.\n",
      "            See [callbacks](/callbacks).\n",
      "        max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n",
      "            input only. Maximum size for the generator queue.\n",
      "            If unspecified, `max_queue_size` will default to 10.\n",
      "        workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
      "            only. Maximum number of processes to spin up when using\n",
      "            process-based threading. If unspecified, `workers` will default\n",
      "            to 1. If 0, will execute the generator on the main thread.\n",
      "        use_multiprocessing: Boolean. Used for generator or\n",
      "            `keras.utils.Sequence` input only. If `True`, use process-based\n",
      "            threading. If unspecified, `use_multiprocessing` will default to\n",
      "            `False`. Note that because this implementation relies on\n",
      "            multiprocessing, you should not pass non-picklable arguments to\n",
      "            the generator as they can't be passed easily to children processes.\n",
      "    \n",
      "    # Returns\n",
      "        Numpy array(s) of predictions.\n",
      "    \n",
      "    # Raises\n",
      "        ValueError: In case of mismatch between the provided\n",
      "            input data and the model's expectations,\n",
      "            or in case a stateful model receives a number of samples\n",
      "            that is not a multiple of the batch size.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "help(keras.models.Sequential.predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[35.551178 ],\n",
       "       [41.087395 ],\n",
       "       [44.214478 ],\n",
       "       [14.505646 ],\n",
       "       [-1.5174484]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted_A=r_model.predict(X_test_A)\n",
    "y_predicted_A[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "492.02376377906336"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE0_A=mean_squared_error(y_test_A,y_predicted_A) #mean_squared_error using Sciki-learn\n",
    "MSE0_A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do find the same mean squared error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Repeating steps 1-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration # 0\n",
      "Iteration # 1\n",
      "Iteration # 2\n",
      "Iteration # 3\n",
      "Iteration # 4\n",
      "Iteration # 5\n",
      "Iteration # 6\n",
      "Iteration # 7\n",
      "Iteration # 8\n",
      "Iteration # 9\n",
      "Iteration # 10\n",
      "Iteration # 11\n",
      "Iteration # 12\n",
      "Iteration # 13\n",
      "Iteration # 14\n",
      "Iteration # 15\n",
      "Iteration # 16\n",
      "Iteration # 17\n",
      "Iteration # 18\n",
      "Iteration # 19\n",
      "Iteration # 20\n",
      "Iteration # 21\n",
      "Iteration # 22\n",
      "Iteration # 23\n",
      "Iteration # 24\n",
      "Iteration # 25\n",
      "Iteration # 26\n",
      "Iteration # 27\n",
      "Iteration # 28\n",
      "Iteration # 29\n",
      "Iteration # 30\n",
      "Iteration # 31\n",
      "Iteration # 32\n",
      "Iteration # 33\n",
      "Iteration # 34\n",
      "Iteration # 35\n",
      "Iteration # 36\n",
      "Iteration # 37\n",
      "Iteration # 38\n",
      "Iteration # 39\n",
      "Iteration # 40\n",
      "Iteration # 41\n",
      "Iteration # 42\n",
      "Iteration # 43\n",
      "Iteration # 44\n",
      "Iteration # 45\n",
      "Iteration # 46\n",
      "Iteration # 47\n",
      "Iteration # 48\n",
      "Iteration # 49\n"
     ]
    }
   ],
   "source": [
    "error_list_A=[MSE0_A]\n",
    "\n",
    "for i in range(50):\n",
    "    print(\"Iteration #\", i)\n",
    "    X_train_A, X_test_A, y_train_A, y_test_A=train_test_split(X,y,test_size=0.3)\n",
    "    r_model.fit(X_train_A, y_train_A, epochs=50, verbose=0)\n",
    "    r_model.evaluate(X_test_A, y_test_A, verbose=0)\n",
    "    y_predicted_A=r_model.predict(X_test_A)\n",
    "    error_list_A.append(mean_squared_error(y_test_A,y_predicted_A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[492.02376377906336,\n",
       " 183.6263177775172,\n",
       " 164.87005879996616,\n",
       " 164.97663272406012,\n",
       " 162.76349588002296,\n",
       " 163.5653750641188,\n",
       " 150.51765332569582,\n",
       " 168.5082875761389,\n",
       " 144.2888772282146,\n",
       " 162.3766801359316,\n",
       " 175.13219946403393,\n",
       " 151.81946817940326,\n",
       " 156.59481572433953,\n",
       " 167.05323611877924,\n",
       " 163.52698188801486,\n",
       " 170.30816339466978,\n",
       " 153.05908495704847,\n",
       " 145.54182592395915,\n",
       " 150.79624543331306,\n",
       " 154.25718628653814,\n",
       " 162.0934597835949,\n",
       " 149.0377022756831,\n",
       " 145.40211641657973,\n",
       " 174.0040784482234,\n",
       " 158.03388422309035,\n",
       " 154.0537807212556,\n",
       " 160.75651216469632,\n",
       " 158.72336651349,\n",
       " 134.72450199935034,\n",
       " 147.1260346285353,\n",
       " 134.24167272897498,\n",
       " 169.90605653639116,\n",
       " 165.62574960759576,\n",
       " 151.50012042927204,\n",
       " 140.38490886638817,\n",
       " 160.9510955818208,\n",
       " 154.102039596027,\n",
       " 148.57567137410243,\n",
       " 173.89898627759814,\n",
       " 155.59150637934246,\n",
       " 160.13208226503693,\n",
       " 155.25543686449086,\n",
       " 153.62161396483984,\n",
       " 142.3908641369666,\n",
       " 157.44643472388265,\n",
       " 152.92027776686263,\n",
       " 148.3013196841121,\n",
       " 155.85212123974821,\n",
       " 148.03482157109846,\n",
       " 149.45800231128248,\n",
       " 159.9974026638218]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_list_A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reporting (statistical analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean,pstdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163.2892151255879"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_MSE_A=mean(error_list_A)\n",
    "avg_MSE_A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After 50 The average mean squared error is 160 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47.57406374405055"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma_MSE_A=pstdev(error_list_A)\n",
    "sigma_MSE_A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The population standard deviation is 10.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part B - Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
       "0   540.0                 0.0      0.0  162.0               2.5   \n",
       "1   540.0                 0.0      0.0  162.0               2.5   \n",
       "2   332.5               142.5      0.0  228.0               0.0   \n",
       "3   332.5               142.5      0.0  228.0               0.0   \n",
       "4   198.6               132.4      0.0  192.0               0.0   \n",
       "\n",
       "   Coarse Aggregate  Fine Aggregate  \n",
       "0            1040.0           676.0  \n",
       "1            1055.0           676.0  \n",
       "2             932.0           594.0  \n",
       "3             932.0           594.0  \n",
       "4             978.4           825.5  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=concrete_data['Strength']\n",
    "X=concrete_data.drop(['Strength','Age'], axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.476712</td>\n",
       "      <td>-0.856472</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>-0.916319</td>\n",
       "      <td>-0.620147</td>\n",
       "      <td>0.862735</td>\n",
       "      <td>-1.217079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.476712</td>\n",
       "      <td>-0.856472</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>-0.916319</td>\n",
       "      <td>-0.620147</td>\n",
       "      <td>1.055651</td>\n",
       "      <td>-1.217079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.491187</td>\n",
       "      <td>0.795140</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>2.174405</td>\n",
       "      <td>-1.038638</td>\n",
       "      <td>-0.526262</td>\n",
       "      <td>-2.239829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.491187</td>\n",
       "      <td>0.795140</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>2.174405</td>\n",
       "      <td>-1.038638</td>\n",
       "      <td>-0.526262</td>\n",
       "      <td>-2.239829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.790075</td>\n",
       "      <td>0.678079</td>\n",
       "      <td>-0.846733</td>\n",
       "      <td>0.488555</td>\n",
       "      <td>-1.038638</td>\n",
       "      <td>0.070492</td>\n",
       "      <td>0.647569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Cement  Blast Furnace Slag   Fly Ash     Water  Superplasticizer  \\\n",
       "0  2.476712           -0.856472 -0.846733 -0.916319         -0.620147   \n",
       "1  2.476712           -0.856472 -0.846733 -0.916319         -0.620147   \n",
       "2  0.491187            0.795140 -0.846733  2.174405         -1.038638   \n",
       "3  0.491187            0.795140 -0.846733  2.174405         -1.038638   \n",
       "4 -0.790075            0.678079 -0.846733  0.488555         -1.038638   \n",
       "\n",
       "   Coarse Aggregate  Fine Aggregate  \n",
       "0          0.862735       -1.217079  \n",
       "1          1.055651       -1.217079  \n",
       "2         -0.526262       -2.239829  \n",
       "3         -0.526262       -2.239829  \n",
       "4          0.070492        0.647569  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_norm=(X-X.mean())/X.std()\n",
    "X_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration # 0\n",
      "Iteration # 1\n",
      "Iteration # 2\n",
      "Iteration # 3\n",
      "Iteration # 4\n",
      "Iteration # 5\n",
      "Iteration # 6\n",
      "Iteration # 7\n",
      "Iteration # 8\n",
      "Iteration # 9\n",
      "Iteration # 10\n",
      "Iteration # 11\n",
      "Iteration # 12\n",
      "Iteration # 13\n",
      "Iteration # 14\n",
      "Iteration # 15\n",
      "Iteration # 16\n",
      "Iteration # 17\n",
      "Iteration # 18\n",
      "Iteration # 19\n",
      "Iteration # 20\n",
      "Iteration # 21\n",
      "Iteration # 22\n",
      "Iteration # 23\n",
      "Iteration # 24\n",
      "Iteration # 25\n",
      "Iteration # 26\n",
      "Iteration # 27\n",
      "Iteration # 28\n",
      "Iteration # 29\n",
      "Iteration # 30\n",
      "Iteration # 31\n",
      "Iteration # 32\n",
      "Iteration # 33\n",
      "Iteration # 34\n",
      "Iteration # 35\n",
      "Iteration # 36\n",
      "Iteration # 37\n",
      "Iteration # 38\n",
      "Iteration # 39\n",
      "Iteration # 40\n",
      "Iteration # 41\n",
      "Iteration # 42\n",
      "Iteration # 43\n",
      "Iteration # 44\n",
      "Iteration # 45\n",
      "Iteration # 46\n",
      "Iteration # 47\n",
      "Iteration # 48\n",
      "Iteration # 49\n",
      "Iteration # 50\n"
     ]
    }
   ],
   "source": [
    "error_list_B=[]\n",
    "\n",
    "for i in range(51):\n",
    "    print(\"Iteration #\", i)\n",
    "    X_train_B, X_test_B, y_train_B, y_test_B=train_test_split(X_norm,y,test_size=0.3)\n",
    "    r_model.fit(X_train_B, y_train_B, epochs=50, verbose=0)\n",
    "    r_model.evaluate(X_test_B, y_test_B, verbose=0)\n",
    "    y_predicted_B=r_model.predict(X_test_B)\n",
    "    error_list_B.append(mean_squared_error(y_test_B,y_predicted_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[194.5912171700066,\n",
       " 175.47130228652452,\n",
       " 142.0881393507858,\n",
       " 147.82215465911733,\n",
       " 150.42861074655895,\n",
       " 143.14307084194317,\n",
       " 129.76002247965613,\n",
       " 125.75819107277835,\n",
       " 145.15327800505415,\n",
       " 137.88786481770634,\n",
       " 127.14788623171107,\n",
       " 135.91366776311912,\n",
       " 140.9438691671348,\n",
       " 120.64103673128265,\n",
       " 128.7849284924106,\n",
       " 136.8461105673104,\n",
       " 121.54766401419826,\n",
       " 137.60814212066632,\n",
       " 128.60995660097626,\n",
       " 124.33931982335139,\n",
       " 146.31026276920656,\n",
       " 128.1390974379125,\n",
       " 140.58295456859088,\n",
       " 140.8423613578113,\n",
       " 118.01504284038681,\n",
       " 122.29316176464327,\n",
       " 131.7703271946003,\n",
       " 119.12577583906831,\n",
       " 129.23566462189208,\n",
       " 124.29829337310679,\n",
       " 134.2814922347651,\n",
       " 130.65894429740376,\n",
       " 141.47844738043267,\n",
       " 136.87155193689432,\n",
       " 112.66480667175433,\n",
       " 122.29235466672812,\n",
       " 131.4545988534446,\n",
       " 128.2743868803867,\n",
       " 137.552711594681,\n",
       " 118.10016885878018,\n",
       " 129.4867117961278,\n",
       " 130.7464291330025,\n",
       " 133.3482625158875,\n",
       " 129.24768572397207,\n",
       " 118.96040948747915,\n",
       " 121.54321710071268,\n",
       " 125.14573511435844,\n",
       " 126.60280145646628,\n",
       " 116.09358869947887,\n",
       " 131.07541055336844,\n",
       " 136.75808937274536]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_list_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133.09288586349766"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_MSE_B=mean(error_list_B)\n",
    "avg_MSE_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.7747180035397"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma_MSE_B=pstdev(error_list_B)\n",
    "sigma_MSE_B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizing the data drove down the mean squared error. Normalizing the features probably leads to a better model by reducing the weight of certain features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part C - Increase the number of epocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "721/721 [==============================] - 0s 29us/step - loss: 115.6033\n",
      "Epoch 2/100\n",
      "721/721 [==============================] - 0s 27us/step - loss: 115.5585\n",
      "Epoch 3/100\n",
      "721/721 [==============================] - 0s 26us/step - loss: 115.6249\n",
      "Epoch 4/100\n",
      "721/721 [==============================] - 0s 26us/step - loss: 115.6566\n",
      "Epoch 5/100\n",
      "721/721 [==============================] - 0s 28us/step - loss: 115.6002\n",
      "Epoch 6/100\n",
      "721/721 [==============================] - 0s 26us/step - loss: 115.5182\n",
      "Epoch 7/100\n",
      "721/721 [==============================] - 0s 25us/step - loss: 115.5785\n",
      "Epoch 8/100\n",
      "721/721 [==============================] - 0s 26us/step - loss: 115.5491\n",
      "Epoch 9/100\n",
      "721/721 [==============================] - 0s 26us/step - loss: 115.5366\n",
      "Epoch 10/100\n",
      "721/721 [==============================] - 0s 28us/step - loss: 115.5472\n",
      "Epoch 11/100\n",
      "721/721 [==============================] - 0s 26us/step - loss: 115.5692\n",
      "Epoch 12/100\n",
      "721/721 [==============================] - ETA: 0s - loss: 90.31 - 0s 28us/step - loss: 115.4571\n",
      "Epoch 13/100\n",
      "721/721 [==============================] - 0s 28us/step - loss: 115.4604\n",
      "Epoch 14/100\n",
      "721/721 [==============================] - 0s 30us/step - loss: 115.4974\n",
      "Epoch 15/100\n",
      "721/721 [==============================] - ETA: 0s - loss: 100.520 - 0s 29us/step - loss: 115.5097\n",
      "Epoch 16/100\n",
      "721/721 [==============================] - 0s 28us/step - loss: 115.4257\n",
      "Epoch 17/100\n",
      "721/721 [==============================] - 0s 28us/step - loss: 115.5444\n",
      "Epoch 18/100\n",
      "721/721 [==============================] - 0s 26us/step - loss: 115.4440\n",
      "Epoch 19/100\n",
      "721/721 [==============================] - 0s 29us/step - loss: 115.6660\n",
      "Epoch 20/100\n",
      "721/721 [==============================] - 0s 27us/step - loss: 115.4642\n",
      "Epoch 21/100\n",
      "721/721 [==============================] - 0s 28us/step - loss: 115.4796\n",
      "Epoch 22/100\n",
      "721/721 [==============================] - 0s 26us/step - loss: 115.4591\n",
      "Epoch 23/100\n",
      "721/721 [==============================] - 0s 26us/step - loss: 115.4170\n",
      "Epoch 24/100\n",
      "721/721 [==============================] - 0s 28us/step - loss: 115.4814\n",
      "Epoch 25/100\n",
      "721/721 [==============================] - 0s 28us/step - loss: 115.4019\n",
      "Epoch 26/100\n",
      "721/721 [==============================] - 0s 18us/step - loss: 115.5103\n",
      "Epoch 27/100\n",
      "721/721 [==============================] - 0s 18us/step - loss: 115.3672\n",
      "Epoch 28/100\n",
      "721/721 [==============================] - 0s 42us/step - loss: 115.4033\n",
      "Epoch 29/100\n",
      "721/721 [==============================] - 0s 25us/step - loss: 115.4011\n",
      "Epoch 30/100\n",
      "721/721 [==============================] - 0s 25us/step - loss: 115.3706\n",
      "Epoch 31/100\n",
      "721/721 [==============================] - 0s 26us/step - loss: 115.2828\n",
      "Epoch 32/100\n",
      "721/721 [==============================] - 0s 29us/step - loss: 115.3305\n",
      "Epoch 33/100\n",
      "721/721 [==============================] - 0s 26us/step - loss: 115.3217\n",
      "Epoch 34/100\n",
      "721/721 [==============================] - 0s 26us/step - loss: 115.2840\n",
      "Epoch 35/100\n",
      "721/721 [==============================] - 0s 26us/step - loss: 115.2522\n",
      "Epoch 36/100\n",
      "721/721 [==============================] - 0s 26us/step - loss: 115.3290\n",
      "Epoch 37/100\n",
      "721/721 [==============================] - 0s 29us/step - loss: 115.2380\n",
      "Epoch 38/100\n",
      "721/721 [==============================] - 0s 29us/step - loss: 115.3167\n",
      "Epoch 39/100\n",
      "721/721 [==============================] - 0s 28us/step - loss: 115.3091\n",
      "Epoch 40/100\n",
      "721/721 [==============================] - 0s 25us/step - loss: 115.3522\n",
      "Epoch 41/100\n",
      "721/721 [==============================] - 0s 29us/step - loss: 115.2515\n",
      "Epoch 42/100\n",
      "721/721 [==============================] - 0s 26us/step - loss: 115.2431\n",
      "Epoch 43/100\n",
      "721/721 [==============================] - 0s 25us/step - loss: 115.2366\n",
      "Epoch 44/100\n",
      "721/721 [==============================] - 0s 28us/step - loss: 115.1803\n",
      "Epoch 45/100\n",
      "721/721 [==============================] - 0s 29us/step - loss: 115.2658\n",
      "Epoch 46/100\n",
      "721/721 [==============================] - 0s 28us/step - loss: 115.2634\n",
      "Epoch 47/100\n",
      "721/721 [==============================] - 0s 28us/step - loss: 115.2156\n",
      "Epoch 48/100\n",
      "721/721 [==============================] - 0s 26us/step - loss: 115.2107\n",
      "Epoch 49/100\n",
      "721/721 [==============================] - 0s 29us/step - loss: 115.1871\n",
      "Epoch 50/100\n",
      "721/721 [==============================] - 0s 30us/step - loss: 115.1451\n",
      "Epoch 51/100\n",
      "721/721 [==============================] - 0s 28us/step - loss: 115.1778\n",
      "Epoch 52/100\n",
      "721/721 [==============================] - 0s 24us/step - loss: 115.1950\n",
      "Epoch 53/100\n",
      "721/721 [==============================] - 0s 28us/step - loss: 115.1285\n",
      "Epoch 54/100\n",
      "721/721 [==============================] - 0s 29us/step - loss: 115.1660\n",
      "Epoch 55/100\n",
      "721/721 [==============================] - 0s 29us/step - loss: 115.2012\n",
      "Epoch 56/100\n",
      "721/721 [==============================] - 0s 26us/step - loss: 115.1545\n",
      "Epoch 57/100\n",
      "721/721 [==============================] - 0s 26us/step - loss: 115.0801\n",
      "Epoch 58/100\n",
      "721/721 [==============================] - 0s 25us/step - loss: 115.1720\n",
      "Epoch 59/100\n",
      "721/721 [==============================] - 0s 25us/step - loss: 115.1655\n",
      "Epoch 60/100\n",
      "721/721 [==============================] - 0s 26us/step - loss: 115.1316\n",
      "Epoch 61/100\n",
      "721/721 [==============================] - 0s 25us/step - loss: 115.1512\n",
      "Epoch 62/100\n",
      "721/721 [==============================] - 0s 26us/step - loss: 115.2454\n",
      "Epoch 63/100\n",
      "721/721 [==============================] - 0s 26us/step - loss: 115.1190\n",
      "Epoch 64/100\n",
      "721/721 [==============================] - 0s 25us/step - loss: 115.0742\n",
      "Epoch 65/100\n",
      "721/721 [==============================] - 0s 26us/step - loss: 115.0977\n",
      "Epoch 66/100\n",
      "721/721 [==============================] - 0s 26us/step - loss: 115.0721\n",
      "Epoch 67/100\n",
      "721/721 [==============================] - 0s 30us/step - loss: 115.0604\n",
      "Epoch 68/100\n",
      "721/721 [==============================] - 0s 32us/step - loss: 115.0433\n",
      "Epoch 69/100\n",
      "721/721 [==============================] - 0s 28us/step - loss: 115.0719\n",
      "Epoch 70/100\n",
      "721/721 [==============================] - 0s 25us/step - loss: 115.1064\n",
      "Epoch 71/100\n",
      "721/721 [==============================] - 0s 26us/step - loss: 115.0450\n",
      "Epoch 72/100\n",
      "721/721 [==============================] - 0s 25us/step - loss: 115.0356\n",
      "Epoch 73/100\n",
      "721/721 [==============================] - 0s 26us/step - loss: 115.0119\n",
      "Epoch 74/100\n",
      "721/721 [==============================] - 0s 26us/step - loss: 115.0233\n",
      "Epoch 75/100\n",
      "721/721 [==============================] - 0s 25us/step - loss: 115.0128\n",
      "Epoch 76/100\n",
      "721/721 [==============================] - 0s 26us/step - loss: 115.0408\n",
      "Epoch 77/100\n",
      "721/721 [==============================] - 0s 25us/step - loss: 115.0247\n",
      "Epoch 78/100\n",
      "721/721 [==============================] - 0s 25us/step - loss: 115.0378\n",
      "Epoch 79/100\n",
      "721/721 [==============================] - 0s 26us/step - loss: 115.0321\n",
      "Epoch 80/100\n",
      "721/721 [==============================] - 0s 25us/step - loss: 115.0662\n",
      "Epoch 81/100\n",
      "721/721 [==============================] - 0s 26us/step - loss: 115.1364\n",
      "Epoch 82/100\n",
      "721/721 [==============================] - 0s 25us/step - loss: 114.9031\n",
      "Epoch 83/100\n",
      "721/721 [==============================] - 0s 28us/step - loss: 115.0351\n",
      "Epoch 84/100\n",
      "721/721 [==============================] - 0s 28us/step - loss: 114.9313\n",
      "Epoch 85/100\n",
      "721/721 [==============================] - ETA: 0s - loss: 83.93 - 0s 28us/step - loss: 114.9775\n",
      "Epoch 86/100\n",
      "721/721 [==============================] - 0s 26us/step - loss: 114.9854\n",
      "Epoch 87/100\n",
      "721/721 [==============================] - 0s 29us/step - loss: 114.9450\n",
      "Epoch 88/100\n",
      "721/721 [==============================] - 0s 26us/step - loss: 114.9484\n",
      "Epoch 89/100\n",
      "721/721 [==============================] - 0s 25us/step - loss: 115.0628\n",
      "Epoch 90/100\n",
      "721/721 [==============================] - ETA: 0s - loss: 119.431 - 0s 28us/step - loss: 114.9090\n",
      "Epoch 91/100\n",
      "721/721 [==============================] - 0s 25us/step - loss: 115.0680\n",
      "Epoch 92/100\n",
      "721/721 [==============================] - ETA: 0s - loss: 168.550 - 0s 26us/step - loss: 114.9402\n",
      "Epoch 93/100\n",
      "721/721 [==============================] - 0s 26us/step - loss: 114.9464\n",
      "Epoch 94/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "721/721 [==============================] - 0s 26us/step - loss: 114.9593\n",
      "Epoch 95/100\n",
      "721/721 [==============================] - 0s 26us/step - loss: 115.0223\n",
      "Epoch 96/100\n",
      "721/721 [==============================] - 0s 25us/step - loss: 114.8746\n",
      "Epoch 97/100\n",
      "721/721 [==============================] - 0s 25us/step - loss: 114.9994\n",
      "Epoch 98/100\n",
      "721/721 [==============================] - 0s 24us/step - loss: 114.9524\n",
      "Epoch 99/100\n",
      "721/721 [==============================] - 0s 25us/step - loss: 114.9079\n",
      "Epoch 100/100\n",
      "721/721 [==============================] - 0s 24us/step - loss: 114.9682\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x19a23c15788>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the model on the training data using 50 epochs.\n",
    "r_model.fit(X_train_B, y_train_B, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration # 0\n",
      "Iteration # 1\n",
      "Iteration # 2\n",
      "Iteration # 3\n",
      "Iteration # 4\n",
      "Iteration # 5\n",
      "Iteration # 6\n",
      "Iteration # 7\n",
      "Iteration # 8\n",
      "Iteration # 9\n",
      "Iteration # 10\n",
      "Iteration # 11\n",
      "Iteration # 12\n",
      "Iteration # 13\n",
      "Iteration # 14\n",
      "Iteration # 15\n",
      "Iteration # 16\n",
      "Iteration # 17\n",
      "Iteration # 18\n",
      "Iteration # 19\n",
      "Iteration # 20\n",
      "Iteration # 21\n",
      "Iteration # 22\n",
      "Iteration # 23\n",
      "Iteration # 24\n",
      "Iteration # 25\n",
      "Iteration # 26\n",
      "Iteration # 27\n",
      "Iteration # 28\n",
      "Iteration # 29\n",
      "Iteration # 30\n",
      "Iteration # 31\n",
      "Iteration # 32\n",
      "Iteration # 33\n",
      "Iteration # 34\n",
      "Iteration # 35\n",
      "Iteration # 36\n",
      "Iteration # 37\n",
      "Iteration # 38\n",
      "Iteration # 39\n",
      "Iteration # 40\n",
      "Iteration # 41\n",
      "Iteration # 42\n",
      "Iteration # 43\n",
      "Iteration # 44\n",
      "Iteration # 45\n",
      "Iteration # 46\n",
      "Iteration # 47\n",
      "Iteration # 48\n",
      "Iteration # 49\n",
      "Iteration # 50\n"
     ]
    }
   ],
   "source": [
    "error_list_C=[]\n",
    "\n",
    "for i in range(51):\n",
    "    print(\"Iteration #\", i)\n",
    "    X_train_B, X_test_B, y_train_B, y_test_B=train_test_split(X_norm,y,test_size=0.3)\n",
    "    r_model.fit(X_train_B, y_train_B, epochs=100, verbose=0) #Notice the increase in the number of epochs\n",
    "    r_model.evaluate(X_test_B, y_test_B, verbose=0)\n",
    "    y_predicted_C=r_model.predict(X_test_B)\n",
    "    error_list_C.append(mean_squared_error(y_test_B,y_predicted_C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[130.28404182580329,\n",
       " 137.40137468825898,\n",
       " 132.6869539880737,\n",
       " 137.28326542356263,\n",
       " 136.82682981347494,\n",
       " 117.46747378465352,\n",
       " 121.43729774869647,\n",
       " 143.00729086481064,\n",
       " 127.40326043531542,\n",
       " 125.8489151759688,\n",
       " 130.73770781657402,\n",
       " 137.20212687919624,\n",
       " 126.47180847605057,\n",
       " 112.92083761250338,\n",
       " 130.62107058722503,\n",
       " 134.5583725791574,\n",
       " 136.11928021634316,\n",
       " 124.07805955296976,\n",
       " 121.33472886098455,\n",
       " 128.22506072675407,\n",
       " 129.65511734958855,\n",
       " 133.38959388601418,\n",
       " 121.39018534476452,\n",
       " 123.20390197590905,\n",
       " 125.0924076775945,\n",
       " 124.21793782683116,\n",
       " 119.23427091546917,\n",
       " 130.447181462877,\n",
       " 128.94431839606997,\n",
       " 129.88875563378053,\n",
       " 135.72312350109937,\n",
       " 127.01097524363439,\n",
       " 136.5958755204289,\n",
       " 118.05346023528556,\n",
       " 128.16143013756465,\n",
       " 125.05299536899615,\n",
       " 117.30532174476183,\n",
       " 137.39138528414628,\n",
       " 108.80964567321453,\n",
       " 119.70594480023985,\n",
       " 124.3901405272466,\n",
       " 129.46391263282285,\n",
       " 121.14769037628878,\n",
       " 114.31336250363032,\n",
       " 128.3714812857717,\n",
       " 119.21689167088367,\n",
       " 113.76114731093745,\n",
       " 128.18135659189966,\n",
       " 132.76239096944428,\n",
       " 119.57465522453265,\n",
       " 132.3077227481768]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_list_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126.95451640933885"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_MSE_C=mean(error_list_C)\n",
    "avg_MSE_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.459337795890611"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma_MSE_C=pstdev(error_list_C)\n",
    "sigma_MSE_C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing the number of epoch also drove down the mean square error as the model becomes more accurate as it is trained longer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part D - Increase the number of layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_model2=regression_model_custom(7,3,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration # 0\n",
      "Iteration # 1\n",
      "Iteration # 2\n",
      "Iteration # 3\n",
      "Iteration # 4\n",
      "Iteration # 5\n",
      "Iteration # 6\n",
      "Iteration # 7\n",
      "Iteration # 8\n",
      "Iteration # 9\n",
      "Iteration # 10\n",
      "Iteration # 11\n",
      "Iteration # 12\n",
      "Iteration # 13\n",
      "Iteration # 14\n",
      "Iteration # 15\n",
      "Iteration # 16\n",
      "Iteration # 17\n",
      "Iteration # 18\n",
      "Iteration # 19\n",
      "Iteration # 20\n",
      "Iteration # 21\n",
      "Iteration # 22\n",
      "Iteration # 23\n",
      "Iteration # 24\n",
      "Iteration # 25\n",
      "Iteration # 26\n",
      "Iteration # 27\n",
      "Iteration # 28\n",
      "Iteration # 29\n",
      "Iteration # 30\n",
      "Iteration # 31\n",
      "Iteration # 32\n",
      "Iteration # 33\n",
      "Iteration # 34\n",
      "Iteration # 35\n",
      "Iteration # 36\n",
      "Iteration # 37\n",
      "Iteration # 38\n",
      "Iteration # 39\n",
      "Iteration # 40\n",
      "Iteration # 41\n",
      "Iteration # 42\n",
      "Iteration # 43\n",
      "Iteration # 44\n",
      "Iteration # 45\n",
      "Iteration # 46\n",
      "Iteration # 47\n",
      "Iteration # 48\n",
      "Iteration # 49\n",
      "Iteration # 50\n"
     ]
    }
   ],
   "source": [
    "error_list_D=[]\n",
    "for i in range(51):\n",
    "    print(\"Iteration #\", i)\n",
    "    X_train_B, X_test_B, y_train_B, y_test_B=train_test_split(X_norm,y,test_size=0.3)\n",
    "    r_model2.fit(X_train_B, y_train_B, epochs=50, verbose=0) #Notice the increase in the number of epochs\n",
    "    r_model2.evaluate(X_test_B, y_test_B, verbose=0)\n",
    "    y_predicted_D=r_model.predict(X_test_B)\n",
    "    error_list_D.append(mean_squared_error(y_test_B,y_predicted_D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119.61728475650554"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_MSE_D=mean(error_list_D)\n",
    "avg_MSE_D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.381524690789036"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma_MSE_D=pstdev(error_list_D)\n",
    "sigma_MSE_D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, increasing the number of hidden layers also drove down the mean squared error as the model was gaining in complexity"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
